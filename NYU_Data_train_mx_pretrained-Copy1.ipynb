{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading NYU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "\n",
    "import timeit\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(os.path.isfile('../bedrooms_part3/bedroom_0041/bedroom_0041_x.mat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "class DepthDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_files=[]\n",
    "        folders=os.listdir(data_dir+'/RGB')\n",
    "        for folder in folders:\n",
    "            subfolders=os.listdir(data_dir+'/RGB/'+folder)\n",
    "            for subfolder in subfolders:\n",
    "                if subfolder.startswith('.'):\n",
    "                    continue\n",
    "                files=os.listdir(data_dir+'/RGB/'+folder+'/'+subfolder)\n",
    "                for file in files:\n",
    "                    if file.endswith('.mat'):\n",
    "                        \n",
    "                        self.data_files.append(folder+'/'+ subfolder+'/'+file)\n",
    "            self.data_dir=data_dir\n",
    "#         sort(self.data_files)      \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        name=self.data_files[index]\n",
    "        img=torch.from_numpy(h5py.File(self.data_dir+'/RGB/'+name,'r')['rgbOut'].value).float()\n",
    "        depth=torch.from_numpy(h5py.File(self.data_dir+'/DEP/'+name,'r')['depthOut'].value).float()\n",
    "        return img,depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset=DepthDataset('../BiggerData')\n",
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter((torch.randperm(self.num_samples)+self.start).long())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_TRAIN: 15257 ,NUM_VAL: 1696\n"
     ]
    }
   ],
   "source": [
    "N=dataset.__len__()\n",
    "NUM_TRAIN = int(N*0.9)\n",
    "NUM_VAL = N-NUM_TRAIN\n",
    "print(\"NUM_TRAIN:\",NUM_TRAIN,\",NUM_VAL:\",NUM_VAL)\n",
    "batch_size=6\n",
    "loader_train = DataLoader(dataset, batch_size=batch_size, sampler=ChunkSampler(NUM_TRAIN, 0),num_workers=8)\n",
    "loader_val = DataLoader(dataset, batch_size=batch_size, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN),num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2543\n"
     ]
    }
   ],
   "source": [
    "# image size = [304, 228]\n",
    "# depth size = [74,55]\n",
    "print(len(loader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-2-002f92b3a5d5>\", line 21, in __getitem__\n    depth=torch.from_numpy(h5py.File(self.data_dir+'/DEP/'+name,'r')['depthOut'].value).float()\n  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/h5py/_hl/files.py\", line 271, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/h5py/_hl/files.py\", line 101, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper (/tmp/pip-huypgcah-build/h5py/_objects.c:2840)\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper (/tmp/pip-huypgcah-build/h5py/_objects.c:2798)\n  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open (/tmp/pip-huypgcah-build/h5py/h5f.c:2117)\nOSError: Unable to open file (Unable to open file: name = '../biggerdata/dep/bedrooms_part5/bedroom_0095/bedroom_0095_196.mat', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c3e7de6c602b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[0mnext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[1;31m# Python 2 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cs231n/myVE35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Traceback (most recent call last):\n  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-2-002f92b3a5d5>\", line 21, in __getitem__\n    depth=torch.from_numpy(h5py.File(self.data_dir+'/DEP/'+name,'r')['depthOut'].value).float()\n  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/h5py/_hl/files.py\", line 271, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n  File \"/home/cs231n/myVE35/lib/python3.5/site-packages/h5py/_hl/files.py\", line 101, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper (/tmp/pip-huypgcah-build/h5py/_objects.c:2840)\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper (/tmp/pip-huypgcah-build/h5py/_objects.c:2798)\n  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open (/tmp/pip-huypgcah-build/h5py/h5f.c:2117)\nOSError: Unable to open file (Unable to open file: name = '../biggerdata/dep/bedrooms_part5/bedroom_0095/bedroom_0095_196.mat', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)\n"
     ]
    }
   ],
   "source": [
    "for t,(x,y) in loader_train:\n",
    "    print (t)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['res3d_branch2c', 'bn2b_branch2c', 'layer2x_br2_BN', 'layer1', 'bn3b_branch2b', 'res2a_branch2c', 'res4a_branch1', 'res4e_branch2c', 'res3a_branch2b', 'layer16x_br1_ConvC', 'res5c_branch2c', 'layer8x_br1_BN', 'res2a_branch2a', 'res3c_branch2a', 'res5a_branch2b', 'res5b_branch2b', 'bn4b_branch2c', 'res3b_branch2a', 'bn2b_branch2b', 'res5b_branch2a', 'bn4a_branch2a', 'res2c_branch2c', 'res4a_branch2b', 'bn5a_branch2a', 'bn4f_branch2a', 'bn4a_branch2b', 'bn2a_branch2a', 'bn5c_branch2b', 'layer2x_br1_ConvB', 'bn4f_branch2c', 'bn4c_branch2c', 'layer8x_br1_ConvC', 'res4b_branch2a', 'layer4x_br1_BN', 'layer4x_BN', 'layer16x_br2_ConvA', 'layer16x_br2_ConvB', 'layer16x_br1_ConvD', 'bn2c_branch2c', 'res2c_branch2b', 'layer8x_Conv', 'bn4f_branch2b', 'res5c_branch2b', 'bn2b_branch2a', 'layer16x_br2_ConvC', 'bn4d_branch2b', 'layer8x_br2_ConvA', 'layer2x_br1_BN', 'layer16x_br1_ConvA', 'layer16x_br2_ConvD', 'bn4a_branch2c', 'ConvPred', 'bn3a_branch1', 'layer4x_br1_ConvA', 'bn4e_branch2c', 'res5a_branch2c', 'layer2x_br2_ConvA', 'layer2x_br1_ConvC', 'bn4c_branch2b', 'bn5a_branch1', 'res4b_branch2c', 'conv1', 'res4a_branch2a', 'res4c_branch2c', 'bn5a_branch2b', 'bn5b_branch2a', 'layer8x_BN', 'res4f_branch2c', 'bn4d_branch2c', 'res4b_branch2b', 'res5a_branch2a', 'res5c_branch2a', 'res4e_branch2a', 'res5b_branch2c', 'res4d_branch2a', 'bn2a_branch2c', 'res2a_branch2b', 'bn4c_branch2a', 'layer16x_BN', 'bn3d_branch2a', 'bn2c_branch2a', 'layer4x_br2_BN', 'layer4x_br2_ConvA', 'layer2x_br2_ConvC', 'bn_conv1', 'bn3c_branch2b', 'res2b_branch2c', 'layer8x_br1_ConvB', 'layer16x_br1_BN', 'res3b_branch2b', 'bn3c_branch2a', 'bn3a_branch2c', 'layer16x_br2_BN', 'bn5a_branch2c', 'bn2c_branch2b', 'res4e_branch2b', 'layer1_BN', 'bn5b_branch2c', 'res2b_branch2a', 'res3a_branch2c', 'bn4e_branch2b', 'layer2x_br1_ConvA', 'res2a_branch1', 'bn3a_branch2a', 'layer2x_Conv', 'bn3a_branch2b', 'layer8x_br2_BN', 'bn4a_branch1', 'bn4d_branch2a', 'bn2a_branch2b', 'res3a_branch2a', 'bn4b_branch2b', 'layer4x_br1_ConvD', 'res4d_branch2c', 'res2b_branch2b', 'res4c_branch2a', 'res4c_branch2b', 'bn5c_branch2a', 'res3d_branch2b', 'layer2x_br2_ConvB', 'bn3b_branch2a', 'bn3b_branch2c', 'layer8x_br2_ConvB', 'layer4x_br2_ConvB', 'res3c_branch2c', 'bn5b_branch2b', 'layer4x_br2_ConvC', 'layer4x_br1_ConvB', 'bn3d_branch2b', 'bn3d_branch2c', 'layer8x_br2_ConvD', 'layer4x_Conv', 'bn3c_branch2c', 'res3c_branch2b', 'layer8x_br1_ConvA', 'layer2x_BN', 'layer2x_br1_ConvD', 'layer16x_br1_ConvB', 'layer4x_br2_ConvD', 'layer8x_br2_ConvC', 'res4d_branch2b', 'res4f_branch2b', 'res5a_branch1', 'layer4x_br1_ConvC', 'bn4e_branch2a', 'bn5c_branch2c', 'res3b_branch2c', 'res2c_branch2a', 'res3a_branch1', 'res4a_branch2c', 'res3d_branch2a', 'bn2a_branch1', 'layer8x_br1_ConvD', 'res4f_branch2a', 'layer2x_br2_ConvD', 'layer16x_Conv', 'bn4b_branch2a'])\n"
     ]
    }
   ],
   "source": [
    "pretrain = np.load('NYU_ResNet-UpProj.npy',encoding='latin1')\n",
    "print(pretrain.item().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 512, 256)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain.item()['layer4x_br1_ConvB']['weights'].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mat File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('NYU_ResNet-UpProj.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vars', '__globals__', 'meta', '__version__', 'layers', '__header__', 'params'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7, 3, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['params'][0][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1_filter = mat['params'][0][0][1].transpose([3,2,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat['params'][0][1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1_bias = mat['params'][0][1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True),\n",
       " ReLU (inplace),\n",
       " MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1)),\n",
       " Sequential (\n",
       "   (0): Bottleneck (\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "     (downsample): Sequential (\n",
       "       (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck (\n",
       "     (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (2): Bottleneck (\n",
       "     (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       " ),\n",
       " Sequential (\n",
       "   (0): Bottleneck (\n",
       "     (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "     (downsample): Sequential (\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck (\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (2): Bottleneck (\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (3): Bottleneck (\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       " ),\n",
       " Sequential (\n",
       "   (0): Bottleneck (\n",
       "     (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "     (downsample): Sequential (\n",
       "       (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck (\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (2): Bottleneck (\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (3): Bottleneck (\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (4): Bottleneck (\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (5): Bottleneck (\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       " ),\n",
       " Sequential (\n",
       "   (0): Bottleneck (\n",
       "     (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "     (downsample): Sequential (\n",
       "       (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck (\n",
       "     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (2): Bottleneck (\n",
       "     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       " ),\n",
       " AvgPool2d (\n",
       " ),\n",
       " Linear (2048 -> 1000)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod[0].weight.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod[0] = nn.Conv2d(3,64,7,stride=2, padding=3,bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod[0].weight.data = torch.from_numpy(conv1_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod[0].bias.data = torch.from_numpy(conv1_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod[1].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod[1]._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod[4][0].conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet50 = torch.nn.Sequential(*mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cropMore(nn.Module):\n",
    "    def forward(self,x):\n",
    "        N,C,H,W = x.size()\n",
    "        return x[:,:,0:H-6,0:W-9].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class unpooling(nn.Module):\n",
    "    def __init__(self,H,W):\n",
    "        super(unpooling, self).__init__()\n",
    "        self.indices = torch.zeros(H,W)\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                self.indices[i,j] = i*2*2*W+j*2\n",
    "        self.unpool = nn.MaxUnpool2d(2)\n",
    "    def forward(self, x):\n",
    "        N,C,H,W = x.size()\n",
    "        indices = self.indices.expand(N,C,H,W)\n",
    "        y = self.unpool(x, Variable(indices.type(torch.cuda.LongTensor),requires_grad=False))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class upsampling(nn.Module):\n",
    "    def __init__(self,C,H,W):\n",
    "        super(upsampling, self).__init__()\n",
    "        self.unpooling = unpooling(H,W)\n",
    "        self.conv5 = nn.Conv2d(C,int(C/2),5,stride = 1,padding=2)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(int(C/2),int(C/2),3,stride = 1,padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(C,int(C/2),5,stride = 1,padding=2)\n",
    "    def forward(self, x):\n",
    "        y0 = self.unpooling(x)\n",
    "        y1 = self.conv5(y0)\n",
    "        y1 = self.ReLU(y1)\n",
    "        y1 = self.conv3(y1)\n",
    "        y2 = self.conv5_2(y0)\n",
    "        y3 = y1+y2\n",
    "        y = self.ReLU(y3)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upsample = torch.nn.Sequential(\n",
    "    nn.Conv2d(2048,1024,1,stride = 1,padding=0),\n",
    "    nn.BatchNorm2d(1024), #1024*10*8\n",
    "    upsampling(1024,10,8),\n",
    "    upsampling(512,20,16),\n",
    "    upsampling(256,40,32),\n",
    "    #upsampling(128,80,64),\n",
    "    nn.Conv2d(128,1,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    cropMore()\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resnet50.type(dtype)\n",
    "upsample.type(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t,(x,y) in enumerate(loader_train):\n",
    "    x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "    #pred=new_model(x_var)\n",
    "    x1 = resnet50(x_var)\n",
    "    pred = upsample(x1)\n",
    "    print(pred.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testModel = nn.MaxPool2d(2,2,return_indices = True)\n",
    "testModel.type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_var=Variable(torch.zeros(1,3,6,10).type(dtype),requires_grad=False)\n",
    "#pred=new_model(x_var)\n",
    "y,ind = testModel(x_var)\n",
    "print(x_var.size())\n",
    "print(y.size())\n",
    "print(ind.size())\n",
    "print(ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testModel = unpooling(10,8)\n",
    "testModel.type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_var=Variable(torch.ones(1,4,10,8).type(dtype),requires_grad=False)\n",
    "#pred=new_model(x_var)\n",
    "y = testModel(x_var)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#images_var=Variable(images_pytorch.type(dtype),requires_grad=False)\n",
    "#depths_var=Variable(depths_pytorch.type(dtype),requires_grad=False)\n",
    "\n",
    "def loss_log(pred,y):\n",
    "    ep = 1e-6\n",
    "    N,W,H = pred.size()\n",
    "    pred = pred.contiguous().view(N,-1)\n",
    "    y = y.view(N,-1)\n",
    "    y = y+ep\n",
    "    d = pred - y.log()\n",
    "    d[y <= 0] = 0\n",
    "    n = W*H\n",
    "    loss = (d.pow(2).sum(1) / n - 0.5 / n/n * d.sum(1).pow(2)).sum()\n",
    "    loss /= N\n",
    "    return loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr=1e-6\n",
    "reg=1e-4\n",
    "adam_optim2=optim.Adam(resnet50.parameters(),lr=lr,weight_decay=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=1e-5\n",
    "reg=1e-4\n",
    "adam_optim=optim.Adam(upsample.parameters(),lr=lr,weight_decay=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "print_every=50\n",
    "\n",
    "def train(model, loss_fn, optimizer, num_epochs = 1, plot_every = 2):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # set the model to training mode, only effect batchnorm and dropout\n",
    "        avg_train_loss=0\n",
    "        num_batches=0\n",
    "        for t,(x,y) in enumerate(loader_train):\n",
    "            x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "            y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "            x1 = resnet50(x_var)\n",
    "            pred = model(x1)\n",
    "            loss = loss_fn(pred, y_var)\n",
    "            #losses.append(loss.data.cpu().numpy())\n",
    "            \n",
    "            if (t+1) % print_every==0:\n",
    "                print('t = %d, loss = %.4f' % (t+1, loss.data[0]))\n",
    "            avg_train_loss+=loss.data[0]\n",
    "            num_batches+=1\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del x,y\n",
    "        avg_train_loss/=num_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        num_batches=0\n",
    "        avg_val_loss=0\n",
    "        for t,(x,y) in enumerate(loader_val):\n",
    "            x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "            y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "            x1 = resnet50(x_var)\n",
    "            pred = model(x1)\n",
    "            loss=loss_fn(pred,y_var)\n",
    "            avg_val_loss+=loss.data[0]\n",
    "            num_batches+=1\n",
    "            del x,y\n",
    "        avg_val_loss/=num_batches\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(\"epoch:\",epoch,\"average training loss: %.2f\"%avg_train_loss,\"validation loss: %.2f\" %avg_val_loss)\n",
    "        if(epoch % plot_every == 0):\n",
    "            #with open('losses_ep'+ str(epoch)+ '.pickle', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "            #    pickle.dump([train_losses,val_losses], f)\n",
    "            #torch.save(model.state_dict(), 'alldata_dict_ep'+str(epoch))\n",
    "            plt.plot(train_losses)\n",
    "            plt.plot(val_losses)\n",
    "        \n",
    "            \n",
    "\n",
    "train(upsample,loss_log,adam_optim,num_epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train(upsample,loss_log,adam_optim,num_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "# visualize 5 images\n",
    "NUM_SHOW=6\n",
    "for t,(x,y) in enumerate(loader_train):\n",
    "    x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "    y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "    upsample.train(False)\n",
    "    x1 = resnet50(x_var)\n",
    "    pred = upsample(x1)\n",
    "    x_var=x_var.cpu()\n",
    "    y_var=y_var.cpu()\n",
    "    pred=pred.cpu()\n",
    "    for i in range(NUM_SHOW):\n",
    "        plt.subplot(3,NUM_SHOW,i+1)\n",
    "        img=x_var[i,:,:,:].data.numpy()\n",
    "        img=np.rollaxis(img,0,3)\n",
    "        imshow_noax(img,False)\n",
    "        plt.subplot(3,NUM_SHOW,NUM_SHOW+i+1)\n",
    "        img=y_var[i,:,:].data.numpy()\n",
    "        imshow_noax(img)\n",
    "        plt.subplot(3,NUM_SHOW,2*NUM_SHOW+i+1)\n",
    "        img=pred[i,:,:].data.numpy()\n",
    "        img = np.exp(img)\n",
    "        imshow_noax(img)\n",
    "    break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(loader, model):\n",
    "    ep = 1e-7\n",
    "\n",
    "    thresh_1 = 0\n",
    "    thresh_2 = 0\n",
    "    abs_diff = 0\n",
    "    rmse = 0\n",
    "\n",
    "    for t,(x,y) in enumerate(loader):\n",
    "        x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "        y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "        model.train(False)\n",
    "        x1 = resnet50(x_var)\n",
    "        pred = model(x1)\n",
    "\n",
    "        #print(y_var.data.cpu().numpy())\n",
    "        y_var=y_var.data.cpu().numpy()\n",
    "        y_var = np.exp(y_var) + ep\n",
    "        pred=pred.data.cpu().numpy() + ep\n",
    "        num_var = np.shape(y_var)[0]*np.shape(y_var)[1]*np.shape(y_var)[2]\n",
    "\n",
    "        # threshold\n",
    "        thresh_mat = np.zeros_like(y_var)\n",
    "        thresh_mat[np.maximum(y_var / pred, pred / y_var) < 1.25] = 1\n",
    "        thresh_1 += np.sum(thresh_mat)\n",
    "        thresh_2 += num_var\n",
    "        #print('t1 = %d, t2 = %d', thresh_1, thresh_2)\n",
    "\n",
    "        # relative absolute diffe\n",
    "        abs_diff += np.sum(np.absolute(y_var - pred) / y_var) / num_var\n",
    "\n",
    "        rmse += np.sqrt(np.sum((y_var - pred) * (y_var - pred)) / num_var)\n",
    "        \n",
    "\n",
    "\n",
    "    abs_diff /= len(loader)\n",
    "    rmse /= len(loader)\n",
    "\n",
    "    print('percentage within threshold: ', thresh_1 / thresh_2)\n",
    "    print('relative absolute diff = ', abs_diff)\n",
    "    print('rmse = ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate(loader_val, upsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, loss_fn, optimizer, optimizer2, num_epochs = 1, plot_every = 10):\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # set the model to training mode, only effect batchnorm and dropout\n",
    "        avg_train_loss=0\n",
    "        num_batches=0\n",
    "        for t,(x,y) in enumerate(loader_train):\n",
    "            x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "            y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "            x1 = resnet50(x_var)\n",
    "            pred = model(x1)\n",
    "            loss = loss_fn(pred, y_var)\n",
    "            losses.append(loss.data.cpu().numpy())\n",
    "            \n",
    "            if (t+1) % print_every==0:\n",
    "                print('t = %d, loss = %.4f' % (t+1, loss.data[0]))\n",
    "            avg_train_loss+=loss.data[0]\n",
    "            num_batches+=1\n",
    "            optimizer.zero_grad()\n",
    "            optimizer2.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer2.step()\n",
    "            del x,y\n",
    "        avg_train_loss/=num_batches\n",
    "        num_batches=0\n",
    "        avg_val_loss=0\n",
    "        for t,(x,y) in enumerate(loader_val):\n",
    "            x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "            y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "            x1 = resnet50(x_var)\n",
    "            pred = model(x1)\n",
    "            loss=loss_fn(pred,y_var)\n",
    "            avg_val_loss+=loss.data[0]\n",
    "            num_batches+=1\n",
    "            del x,y\n",
    "        avg_val_loss/=num_batches\n",
    "        print(\"epoch:\",epoch,\"average training loss: %.2f\"%avg_train_loss,\"validation loss: %.2f\" %avg_val_loss)\n",
    "        if(epoch % plot_every == 0):\n",
    "            plt.plot(losses)\n",
    "            \n",
    "\n",
    "train(upsample,log_loss,adam_optim,adam_optim2,num_epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del upsample\n",
    "del resnet50\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "# visualize 5 images\n",
    "NUM_SHOW=5\n",
    "for t,(x,y) in enumerate(loader_train):\n",
    "    x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "    y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "    upsample.train(False)\n",
    "    x1 = resnet50(x_var)\n",
    "    pred = upsample(x1)\n",
    "    x_var=x_var.cpu()\n",
    "    y_var=y_var.cpu()\n",
    "    pred=pred.cpu()\n",
    "    for i in range(NUM_SHOW):\n",
    "        plt.subplot(3,NUM_SHOW,i+1)\n",
    "        img=x_var[i,:,:,:].data.numpy()\n",
    "        img=np.rollaxis(img,0,3)\n",
    "        imshow_noax(img,False)\n",
    "        plt.subplot(3,NUM_SHOW,NUM_SHOW+i+1)\n",
    "        img=y_var[i,:,:].data.numpy()\n",
    "        imshow_noax(img)\n",
    "        plt.subplot(3,NUM_SHOW,2*NUM_SHOW+i+1)\n",
    "        img=pred[i,:,:].data.numpy()\n",
    "        img = np.exp(img)\n",
    "        imshow_noax(img)\n",
    "    break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train(upsample,log_loss,adam_optim,adam_optim2,num_epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_SHOW=5\n",
    "for t,(x,y) in enumerate(loader_train):\n",
    "    x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "    y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "    upsample.train(False)\n",
    "    x1 = resnet50(x_var)\n",
    "    pred = upsample(x1)\n",
    "    x_var=x_var.cpu()\n",
    "    y_var=y_var.cpu()\n",
    "    pred=pred.cpu()\n",
    "    for i in range(NUM_SHOW):\n",
    "        plt.subplot(3,NUM_SHOW,i+1)\n",
    "        img=x_var[i,:,:,:].data.numpy()\n",
    "        img=np.rollaxis(img,0,3)\n",
    "        imshow_noax(img,False)\n",
    "        plt.subplot(3,NUM_SHOW,NUM_SHOW+i+1)\n",
    "        img=y_var[i,:,:].data.numpy()\n",
    "        imshow_noax(img)\n",
    "        plt.subplot(3,NUM_SHOW,2*NUM_SHOW+i+1)\n",
    "        img=pred[i,:,:].data.numpy()\n",
    "        img = np.exp(img)\n",
    "        imshow_noax(img)\n",
    "    break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    ep = 1e-7\n",
    "\n",
    "    thresh_1 = 0\n",
    "    thresh_2 = 0\n",
    "    abs_diff = 0\n",
    "    rmse = 0\n",
    "\n",
    "    for t,(x,y) in enumerate(loader):\n",
    "        x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "        y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "        coarse_model.train(False)\n",
    "        pred=coarse_model(x_var)\n",
    "\n",
    "        #print(y_var.data.cpu().numpy())\n",
    "        y_var=y_var.data.cpu().numpy() + ep\n",
    "        pred=pred.data.cpu().numpy() + ep\n",
    "        num_var = np.shape(y_var)[0]*np.shape(y_var)[1]*np.shape(y_var)[2]\n",
    "\n",
    "        # threshold\n",
    "        thresh_mat = np.zeros_like(y_var)\n",
    "        thresh_mat[np.maximum(y_var / pred, pred / y_var) < 1.25] = 1\n",
    "        thresh_1 += np.sum(thresh_mat)\n",
    "        thresh_2 += num_var\n",
    "        #print('t1 = %d, t2 = %d', thresh_1, thresh_2)\n",
    "\n",
    "        # relative absolute diffe\n",
    "        abs_diff += np.sum(np.absolute(y_var - pred) / y_var) / num_var\n",
    "\n",
    "        rmse += np.sqrt(np.sum((y_var - pred) * (y_var - pred)) / num_var)\n",
    "\n",
    "\n",
    "    abs_diff /= len(loader_train)\n",
    "\n",
    "    print('percentage within threshold: ', thresh_1 / thresh_2)\n",
    "    print('relative absolute diff = ', abs_diff)\n",
    "    print('rmse = ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate(loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_overfit(model, loss_fn, optimizer, num_epochs = 1, plot_every = 10):\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # set the model to training mode, only effect batchnorm and dropout\n",
    "        avg_train_loss=0\n",
    "        num_batches=0\n",
    "        for t,(x,y) in enumerate(loader_train):\n",
    "            x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "            y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "            pred=model(x_var)\n",
    "            loss = loss_fn(pred, y_var)\n",
    "            losses.append(loss.data.cpu().numpy())\n",
    "            \n",
    "            if (t+1) % print_every==0:\n",
    "                print('t = %d, loss = %.4f' % (t+1, loss.data[0]))\n",
    "            avg_train_loss+=loss.data[0]\n",
    "            num_batches+=1\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            break\n",
    "        avg_train_loss/=num_batches\n",
    "        num_batches=0\n",
    "\n",
    "        print(\"epoch:\",epoch,\"average training loss: %.2f\"%avg_train_loss)\n",
    "        if(epoch % plot_every == 0):\n",
    "            plt.plot(losses)\n",
    "            \n",
    "\n",
    "train_overfit(coarse_model,loss_log,adam_optim,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_SHOW=5\n",
    "for t,(x,y) in enumerate(loader_train):\n",
    "    x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "    y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "    coarse_model.train(False)\n",
    "    pred=coarse_model(x_var)\n",
    "    x_var=x_var.cpu()\n",
    "    y_var=y_var.cpu()\n",
    "    pred=pred.cpu()\n",
    "    for i in range(NUM_SHOW):\n",
    "        plt.subplot(3,NUM_SHOW,i+1)\n",
    "        img=x_var[i,:,:,:].data.numpy()\n",
    "        img=np.rollaxis(img,0,3)\n",
    "        imshow_noax(img,False)\n",
    "        plt.subplot(3,NUM_SHOW,NUM_SHOW+i+1)\n",
    "        img=y_var[i,:,:].data.numpy()\n",
    "        imshow_noax(img)\n",
    "        plt.subplot(3,NUM_SHOW,2*NUM_SHOW+i+1)\n",
    "        img=pred[i,:,:].data.numpy()\n",
    "        img = np.exp(img)\n",
    "        imshow_noax(img)\n",
    "    break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "a = [1,2,3,4]#np.array([1,2,3,4])\n",
    "a.append(5)\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.zeros(3,3)\n",
    "a[0,1] = 2\n",
    "a[0,2] = 4\n",
    "b = torch.sum(a,0)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UnConv(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        channel1 = nn.Sequential(\n",
    "            nn.MaxUnpool2d(kernel_size=2, stride=None, padding=0),\n",
    "            nn.Conv2d(C,int(C/2),5,stride = 1,padding=2),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        channel1.type(dtype)\n",
    "        return channel1(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
