{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading NYU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "\n",
    "import timeit\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "class DepthDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_files=[]\n",
    "        folders=os.listdir(data_dir+'/RGB')\n",
    "        for folder in folders:\n",
    "            subfolders=os.listdir(data_dir+'/RGB/'+folder)\n",
    "            for subfolder in subfolders:\n",
    "                if subfolder.startswith('.'):\n",
    "                    continue\n",
    "                files=os.listdir(data_dir+'/RGB/'+folder+'/'+subfolder)\n",
    "                for file in files:\n",
    "                    if not os.path.isfile(data_dir+'/DEP/'+folder+'/'+subfolder+'/'+file):\n",
    "                        continue\n",
    "                    if file.endswith('.mat'):\n",
    "                        self.data_files.append(folder+'/'+ subfolder+'/'+file)\n",
    "            self.data_dir=data_dir\n",
    "#         sort(self.data_files)      \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        name=self.data_files[index]\n",
    "        img=torch.from_numpy(h5py.File(self.data_dir+'/RGB/'+name,'r')['rgbOut'].value).float()\n",
    "        depth=torch.from_numpy(h5py.File(self.data_dir+'/DEP/'+name,'r')['depthOut'].value).float()\n",
    "        return img,depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset=DepthDataset('../BiggerData')\n",
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter((torch.randperm(self.num_samples)+self.start).long())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_TRAIN: 10254 ,NUM_VAL: 1140\n"
     ]
    }
   ],
   "source": [
    "N=dataset.__len__()\n",
    "NUM_TRAIN = int(N*0.9)\n",
    "NUM_VAL = N-NUM_TRAIN\n",
    "print(\"NUM_TRAIN:\",NUM_TRAIN,\",NUM_VAL:\",NUM_VAL)\n",
    "batch_size=8\n",
    "loader_train = DataLoader(dataset, batch_size=batch_size, sampler=ChunkSampler(NUM_TRAIN, 0),num_workers=8)\n",
    "loader_val = DataLoader(dataset, batch_size=batch_size, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN),num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282\n"
     ]
    }
   ],
   "source": [
    "# image size = [304, 228]\n",
    "# depth size = [160,128]\n",
    "print(len(loader_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['res4f_branch2a', 'res3a_branch2b', 'bn5b_branch2b', 'layer4x_br1_ConvB', 'bn3d_branch2a', 'layer16x_BN', 'res5a_branch2a', 'res4f_branch2b', 'res4d_branch2b', 'res3d_branch2b', 'res4b_branch2b', 'bn2b_branch2b', 'res4d_branch2a', 'layer8x_br2_BN', 'bn3d_branch2c', 'bn4b_branch2b', 'res3c_branch2b', 'bn2a_branch2b', 'res5c_branch2a', 'res3a_branch1', 'layer16x_Conv', 'layer2x_br2_ConvA', 'res3b_branch2b', 'layer2x_br1_ConvD', 'layer16x_br2_BN', 'layer4x_Conv', 'bn5a_branch2a', 'layer2x_br1_ConvA', 'res2b_branch2b', 'bn5c_branch2b', 'res4c_branch2c', 'bn5b_branch2a', 'layer2x_br2_BN', 'layer8x_Conv', 'bn4d_branch2c', 'bn2a_branch2c', 'res5b_branch2c', 'bn2a_branch2a', 'bn4e_branch2a', 'layer2x_br1_BN', 'res3b_branch2a', 'layer4x_br1_ConvD', 'res4c_branch2a', 'res2c_branch2c', 'layer4x_br2_ConvD', 'bn3c_branch2a', 'res4f_branch2c', 'bn3a_branch1', 'layer8x_br1_ConvA', 'res4b_branch2a', 'res3c_branch2c', 'bn4a_branch1', 'bn_conv1', 'layer2x_br2_ConvD', 'layer8x_br2_ConvD', 'bn5a_branch1', 'bn5c_branch2c', 'ConvPred', 'bn2a_branch1', 'layer8x_br1_ConvC', 'conv1', 'bn3b_branch2a', 'bn2c_branch2b', 'res2a_branch1', 'res4a_branch1', 'bn4f_branch2a', 'bn4d_branch2a', 'bn3c_branch2b', 'bn4b_branch2c', 'res4a_branch2c', 'layer8x_br1_BN', 'layer16x_br2_ConvA', 'layer8x_br1_ConvD', 'bn4b_branch2a', 'layer16x_br2_ConvD', 'res5c_branch2c', 'layer2x_br1_ConvB', 'layer4x_br1_BN', 'res4c_branch2b', 'bn4a_branch2b', 'res4d_branch2c', 'layer16x_br1_ConvD', 'res5b_branch2b', 'res2a_branch2a', 'layer2x_br2_ConvC', 'bn4a_branch2c', 'bn4a_branch2a', 'layer4x_BN', 'layer16x_br2_ConvB', 'layer16x_br1_ConvA', 'bn4f_branch2c', 'res2c_branch2b', 'res2a_branch2c', 'res3d_branch2a', 'layer4x_br2_ConvB', 'res5c_branch2b', 'layer4x_br1_ConvA', 'bn5a_branch2b', 'res2a_branch2b', 'bn5b_branch2c', 'bn2c_branch2a', 'bn5a_branch2c', 'res4e_branch2b', 'bn4c_branch2c', 'bn3b_branch2c', 'bn3b_branch2b', 'res3c_branch2a', 'layer16x_br1_BN', 'bn2c_branch2c', 'bn4e_branch2c', 'layer4x_br2_ConvC', 'layer2x_br1_ConvC', 'layer8x_br2_ConvA', 'layer1', 'res5a_branch1', 'bn4d_branch2b', 'layer4x_br2_BN', 'res4b_branch2c', 'res4a_branch2a', 'layer16x_br1_ConvC', 'res5a_branch2b', 'res2b_branch2a', 'bn4e_branch2b', 'layer2x_BN', 'res2c_branch2a', 'res3b_branch2c', 'res5b_branch2a', 'res3a_branch2c', 'bn5c_branch2a', 'res3a_branch2a', 'layer16x_br2_ConvC', 'layer1_BN', 'layer2x_br2_ConvB', 'bn4c_branch2b', 'res5a_branch2c', 'res4e_branch2a', 'res4e_branch2c', 'layer4x_br2_ConvA', 'bn2b_branch2c', 'layer8x_br2_ConvC', 'bn4f_branch2b', 'res2b_branch2c', 'bn3a_branch2a', 'bn4c_branch2a', 'bn2b_branch2a', 'bn3d_branch2b', 'layer8x_br2_ConvB', 'bn3a_branch2b', 'res4a_branch2b', 'layer8x_BN', 'layer2x_Conv', 'res3d_branch2c', 'bn3c_branch2c', 'layer16x_br1_ConvB', 'layer8x_br1_ConvB', 'bn3a_branch2c', 'layer4x_br1_ConvC'])\n"
     ]
    }
   ],
   "source": [
    "pretrain = np.load('NYU_ResNet-UpProj.npy',encoding='latin1')\n",
    "print(pretrain.item().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 512, 256)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain.item()['layer4x_br2_ConvB']['weights'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': array([-0.00029113,  0.00106764, -0.00150392, ..., -0.00021943,\n",
       "        -0.0002065 ,  0.0047509 ], dtype=float32),\n",
       " 'offset': array([-0.00078779,  0.00016511,  0.00168939, ..., -0.00271009,\n",
       "         0.00010633, -0.0049724 ], dtype=float32),\n",
       " 'scale': array([ 0.07726511,  0.07062423,  0.05010203, ...,  0.06819688,\n",
       "         0.07665947,  0.03478926], dtype=float32),\n",
       " 'variance': array([  1.37350071e-05,   1.22114288e-05,   2.31600643e-05, ...,\n",
       "          1.32349305e-05,   1.13116766e-05,   4.54611363e-05], dtype=float32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain.item()['layer1_BN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mat File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('NYU_ResNet-UpProj.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat['params'][0][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1_filter = mat['params'][0][0][1].transpose([3,2,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat['params'][0][1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1_bias = mat['params'][0][1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True),\n",
       " ReLU (inplace),\n",
       " MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1)),\n",
       " Sequential (\n",
       "   (0): Bottleneck (\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "     (downsample): Sequential (\n",
       "       (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck (\n",
       "     (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (2): Bottleneck (\n",
       "     (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       " ),\n",
       " Sequential (\n",
       "   (0): Bottleneck (\n",
       "     (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "     (downsample): Sequential (\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck (\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (2): Bottleneck (\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (3): Bottleneck (\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       " ),\n",
       " Sequential (\n",
       "   (0): Bottleneck (\n",
       "     (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "     (downsample): Sequential (\n",
       "       (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck (\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (2): Bottleneck (\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (3): Bottleneck (\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (4): Bottleneck (\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (5): Bottleneck (\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       " ),\n",
       " Sequential (\n",
       "   (0): Bottleneck (\n",
       "     (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "     (downsample): Sequential (\n",
       "       (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck (\n",
       "     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       "   (2): Bottleneck (\n",
       "     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "     (relu): ReLU (inplace)\n",
       "   )\n",
       " ),\n",
       " AvgPool2d (\n",
       " ),\n",
       " Linear (2048 -> 1000)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear (2048 -> 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AvgPool2d (\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet50 = torch.nn.Sequential(*mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class fastUpProjection(nn.Module):\n",
    "    def __init__(self,Cin):\n",
    "        super(fastUpProjection, self).__init__()\n",
    "        Cout = int(Cin/2)\n",
    "        self.Cout = Cout\n",
    "        self.br1convA = nn.Conv2d(Cin,Cout,(3,3),stride=1, padding=1,bias=True)\n",
    "        self.br1convB = nn.Conv2d(Cin,Cout,(2,3),stride=1, padding=1,bias=True)\n",
    "        self.br1convC = nn.Conv2d(Cin,Cout,(3,2),stride=1, padding=1,bias=True)\n",
    "        self.br1convD = nn.Conv2d(Cin,Cout,(2,2),stride=1, padding=1,bias=True)\n",
    "        self.br1bn = nn.BatchNorm2d(Cout)\n",
    "        self.br1relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(Cout,Cout,(3,3),stride=1, padding=1,bias=True)\n",
    "        self.bn = nn.BatchNorm2d(Cout)\n",
    "        self.br2convA = nn.Conv2d(Cin,Cout,(3,3),stride=1, padding=1,bias=True)\n",
    "        self.br2convB = nn.Conv2d(Cin,Cout,(2,3),stride=1, padding=1,bias=True)\n",
    "        self.br2convC = nn.Conv2d(Cin,Cout,(3,2),stride=1, padding=1,bias=True)\n",
    "        self.br2convD = nn.Conv2d(Cin,Cout,(2,2),stride=1, padding=1,bias=True)\n",
    "        self.br2bn = nn.BatchNorm2d(Cout)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        N,C,H,W = x.size()\n",
    "        a1 = self.br1convA(x)\n",
    "        b1 = self.br1convB(x)[:,:,:-1,:]\n",
    "        c1 = self.br1convC(x)[:,:,:,:-1]\n",
    "        d1 = self.br1convD(x)[:,:,1:,1:]\n",
    "        #i1 = Variable(torch.zeros((N,self.Cout,2*H,2*W)).type(dtype))\n",
    "        i1 = torch.cat((a1,a1),2)\n",
    "        i1 = torch.cat((i1,i1),3)\n",
    "        #print(i1.size())\n",
    "        i1[:,:,0::2,0::2] = a1\n",
    "        i1[:,:,1::2,0::2] = b1\n",
    "        i1[:,:,0::2,1::2] = c1\n",
    "        i1[:,:,1::2,1::2] = d1\n",
    "        bn1 = self.br1bn(i1)\n",
    "        r1 = self.br1relu(bn1)\n",
    "        c = self.conv(r1)\n",
    "        bn = self.bn(c)\n",
    "        \n",
    "        a2 = self.br2convA(x)\n",
    "        b2 = self.br2convB(x)[:,:,:-1,:]\n",
    "        c2 = self.br2convC(x)[:,:,:,:-1]\n",
    "        d2 = self.br2convD(x)[:,:,1:,1:]\n",
    "        #i2 = Variable(torch.zeros((N,self.Cout,2*H,2*W)).type(dtype))\n",
    "        i2 = torch.cat((a2,a2),2)\n",
    "        i2 = torch.cat((i2,i2),3)\n",
    "        i2[:,:,0::2,0::2] = a2\n",
    "        i2[:,:,1::2,0::2] = b2\n",
    "        i2[:,:,0::2,1::2] = c2\n",
    "        i2[:,:,1::2,1::2] = d2\n",
    "        bn2 = self.br1bn(i2)\n",
    "        \n",
    "        s = bn + bn2\n",
    "        y = self.relu(s)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upsample = torch.nn.Sequential(\n",
    "    nn.Conv2d(2048,1024,1,stride = 1,padding=0),\n",
    "    nn.BatchNorm2d(1024), #1024*10*8\n",
    "    fastUpProjection(1024),\n",
    "    fastUpProjection(512),\n",
    "    fastUpProjection(256),\n",
    "    fastUpProjection(128),\n",
    "    nn.Conv2d(64,1,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (2): fastUpProjection (\n",
       "    (br1convA): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convB): Conv2d(1024, 512, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convC): Conv2d(1024, 512, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convD): Conv2d(1024, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br1relu): ReLU ()\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br2convA): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convB): Conv2d(1024, 512, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convC): Conv2d(1024, 512, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convD): Conv2d(1024, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu): ReLU ()\n",
       "  )\n",
       "  (3): fastUpProjection (\n",
       "    (br1convA): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convB): Conv2d(512, 256, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convC): Conv2d(512, 256, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convD): Conv2d(512, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br1relu): ReLU ()\n",
       "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br2convA): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convB): Conv2d(512, 256, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convC): Conv2d(512, 256, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convD): Conv2d(512, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu): ReLU ()\n",
       "  )\n",
       "  (4): fastUpProjection (\n",
       "    (br1convA): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convB): Conv2d(256, 128, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convC): Conv2d(256, 128, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convD): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br1relu): ReLU ()\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br2convA): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convB): Conv2d(256, 128, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convC): Conv2d(256, 128, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convD): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu): ReLU ()\n",
       "  )\n",
       "  (5): fastUpProjection (\n",
       "    (br1convA): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convB): Conv2d(128, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convC): Conv2d(128, 64, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convD): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br1relu): ReLU ()\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br2convA): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convB): Conv2d(128, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convC): Conv2d(128, 64, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convD): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu): ReLU ()\n",
       "  )\n",
       "  (6): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU ()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.type(dtype)\n",
    "upsample.type(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadConvParameter(conv,data):\n",
    "    assert(conv.weight.data.size() == torch.from_numpy(data['weights'].transpose([3,2,0,1])).size())\n",
    "    conv.weight.data = torch.from_numpy(data['weights'].transpose([3,2,0,1]))\n",
    "    \n",
    "    assert(conv.bias.data.size() == torch.from_numpy(data['biases']).size())\n",
    "    conv.bias.data = torch.from_numpy(data['biases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadBnParameter(bn,data):\n",
    "    assert(bn.weight.data.size() == torch.from_numpy(data['scale']).size())\n",
    "    bn.weight.data = torch.from_numpy(data['scale'])\n",
    "    \n",
    "    assert(bn.bias.data.size() == torch.from_numpy(data['offset']).size())\n",
    "    bn.bias.data = torch.from_numpy(data['offset'])\n",
    "    \n",
    "    assert(bn.running_mean.size() == torch.from_numpy(data['mean']).size())\n",
    "    bn.running_mean = torch.from_numpy(data['mean'])\n",
    "    \n",
    "    assert(bn.running_var.size() == torch.from_numpy(data['variance']).size())\n",
    "    bn.running_var = torch.from_numpy(data['variance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loadConvParameter(upsample[0],pretrain.item()['layer1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loadBnParameter(upsample[1],pretrain.item()['layer1_BN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadUpProjectParameter(upproject,data,name):\n",
    "    loadConvParameter(upproject.br1convA,data[name+'_br1_ConvA'])\n",
    "    loadConvParameter(upproject.br1convB,data[name+'_br1_ConvB'])\n",
    "    loadConvParameter(upproject.br1convC,data[name+'_br1_ConvC'])\n",
    "    loadConvParameter(upproject.br1convD,data[name+'_br1_ConvD'])\n",
    "    loadBnParameter(upproject.br1bn,data[name+'_br1_BN'])\n",
    "    loadConvParameter(upproject.conv,data[name+'_Conv'])\n",
    "    loadBnParameter(upproject.bn,data[name+'_BN'])\n",
    "    \n",
    "    loadConvParameter(upproject.br2convA,data[name+'_br2_ConvA'])\n",
    "    loadConvParameter(upproject.br2convB,data[name+'_br2_ConvB'])\n",
    "    loadConvParameter(upproject.br2convC,data[name+'_br2_ConvC'])\n",
    "    loadConvParameter(upproject.br2convD,data[name+'_br2_ConvD'])\n",
    "    loadBnParameter(upproject.br2bn,data[name+'_br2_BN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loadUpProjectParameter(upsample[2],pretrain.item(),'layer2x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loadUpProjectParameter(upsample[3],pretrain.item(),'layer4x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loadUpProjectParameter(upsample[4],pretrain.item(),'layer8x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadUpProjectParameter(upsample[5],pretrain.item(),'layer16x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadConvParameter(upsample[6],pretrain.item()['ConvPred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (2): fastUpProjection (\n",
       "    (br1convA): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convB): Conv2d(1024, 512, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convC): Conv2d(1024, 512, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convD): Conv2d(1024, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br1relu): ReLU ()\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br2convA): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convB): Conv2d(1024, 512, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convC): Conv2d(1024, 512, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convD): Conv2d(1024, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu): ReLU ()\n",
       "  )\n",
       "  (3): fastUpProjection (\n",
       "    (br1convA): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convB): Conv2d(512, 256, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convC): Conv2d(512, 256, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convD): Conv2d(512, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br1relu): ReLU ()\n",
       "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br2convA): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convB): Conv2d(512, 256, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convC): Conv2d(512, 256, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convD): Conv2d(512, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu): ReLU ()\n",
       "  )\n",
       "  (4): fastUpProjection (\n",
       "    (br1convA): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convB): Conv2d(256, 128, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convC): Conv2d(256, 128, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convD): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br1relu): ReLU ()\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br2convA): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convB): Conv2d(256, 128, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convC): Conv2d(256, 128, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convD): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu): ReLU ()\n",
       "  )\n",
       "  (5): fastUpProjection (\n",
       "    (br1convA): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convB): Conv2d(128, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convC): Conv2d(128, 64, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1convD): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br1bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br1relu): ReLU ()\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (br2convA): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convB): Conv2d(128, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convC): Conv2d(128, 64, kernel_size=(3, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2convD): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (br2bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu): ReLU ()\n",
       "  )\n",
       "  (6): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU ()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.type(dtype)\n",
    "upsample.type(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t,(x,y) in enumerate(loader_train):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t,(x,y) in enumerate(loader_train):\n",
    "    x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "    #pred=new_model(x_var)\n",
    "    x1 = resnet50(x_var)\n",
    "    print(x1.size())\n",
    "    pred = upsample(x1)\n",
    "    print(pred.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#images_var=Variable(images_pytorch.type(dtype),requires_grad=False)\n",
    "#depths_var=Variable(depths_pytorch.type(dtype),requires_grad=False)\n",
    "\n",
    "def loss_log(pred,y):\n",
    "    ep = 1e-6\n",
    "    N,W,H = 0,0,0\n",
    "    pred = pred.squeeze()\n",
    "    if len(pred.size()) == 3:\n",
    "        N,W,H = pred.size()\n",
    "    else:\n",
    "        N = 1\n",
    "        W,H = pred.size()\n",
    "    pred = pred.contiguous().view(N,-1)\n",
    "    y = y.view(N,-1)\n",
    "    y = y+ep\n",
    "    d = pred.log() - y.log()\n",
    "    d[y <= 0] = 0\n",
    "    n = W*H\n",
    "    loss = (d.pow(2).sum(1) / n - 0.5 / n/n * d.sum(1).pow(2)).sum()\n",
    "    loss /= N\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def berHu(pred,y):\n",
    "    N,W,H = 0,0,0\n",
    "    pred = pred.squeeze()\n",
    "    if len(pred.size()) == 3:\n",
    "        N,W,H = pred.size()\n",
    "    else:\n",
    "        N = 1\n",
    "        W,H = pred.size()\n",
    "    pred = pred.contiguous().view(N,-1)\n",
    "    y = y.view(N,-1)\n",
    "    x = torch.abs(pred-y)\n",
    "    \n",
    "    c,_ = torch.max(x,1)\n",
    "    c = c/5.0\n",
    "    c = c.repeat(1,W*H)\n",
    "    l2 = (x.pow(2) + c.pow(2)) / (2*c)\n",
    "    lossN = torch.min(x,l2)\n",
    "    loss = lossN.sum()/(N*H*W)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr=1e-6\n",
    "reg=1e-4\n",
    "adam_optim2=optim.Adam(resnet50.parameters(),lr=lr,weight_decay=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=1e-5\n",
    "reg=1e-4\n",
    "adam_optim=optim.Adam(upsample.parameters(),lr=lr,weight_decay=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "print_every=50\n",
    "\n",
    "def train(model, loss_fn, optimizer, num_epochs = 1, plot_every = 2):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # set the model to training mode, only effect batchnorm and dropout\n",
    "        avg_train_loss=0\n",
    "        num_batches=0\n",
    "        for t,(x,y) in enumerate(loader_train):\n",
    "            x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "            y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "            x1 = resnet50(x_var)\n",
    "            pred = model(x1)\n",
    "            loss = loss_fn(pred, y_var)\n",
    "            #losses.append(loss.data.cpu().numpy())\n",
    "            \n",
    "            if (t+1) % print_every==0:\n",
    "                print('t = %d, loss = %.4f' % (t+1, loss.data[0]))\n",
    "            avg_train_loss+=loss.data[0]\n",
    "            num_batches+=1\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del x,y\n",
    "        avg_train_loss/=num_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        num_batches=0\n",
    "        avg_val_loss=0\n",
    "        for t,(x,y) in enumerate(loader_val):\n",
    "            x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "            y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "            x1 = resnet50(x_var)\n",
    "            pred = model(x1)\n",
    "            loss=loss_fn(pred,y_var)\n",
    "            avg_val_loss+=loss.data[0]\n",
    "            num_batches+=1\n",
    "            del x,y\n",
    "        avg_val_loss/=num_batches\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(\"epoch:\",epoch,\"average training loss: %.2f\"%avg_train_loss,\"validation loss: %.2f\" %avg_val_loss)\n",
    "        if(epoch % plot_every == 0):\n",
    "            #with open('losses_ep'+ str(epoch)+ '.pickle', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "            #    pickle.dump([train_losses,val_losses], f)\n",
    "            #torch.save(model.state_dict(), 'alldata_dict_ep'+str(epoch))\n",
    "            plt.plot(train_losses)\n",
    "            plt.plot(val_losses)\n",
    "        \n",
    "            \n",
    "\n",
    "train(upsample,berHu,adam_optim,num_epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train(upsample,loss_log,adam_optim,num_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "# visualize 5 images\n",
    "NUM_SHOW=6\n",
    "for t,(x,y) in enumerate(loader_train):\n",
    "    x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "    y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "    upsample.train(False)\n",
    "    x1 = resnet50(x_var)\n",
    "    pred = upsample(x1)\n",
    "    x_var=x_var.cpu()\n",
    "    y_var=y_var.cpu()\n",
    "    pred=pred.cpu()\n",
    "    for i in range(NUM_SHOW):\n",
    "        plt.subplot(3,NUM_SHOW,i+1)\n",
    "        img=x_var[i,:,:,:].data.numpy()\n",
    "        img=np.rollaxis(img,0,3)\n",
    "        imshow_noax(img,False)\n",
    "        plt.subplot(3,NUM_SHOW,NUM_SHOW+i+1)\n",
    "        img=y_var[i,:,:].data.numpy()\n",
    "        imshow_noax(img)\n",
    "        plt.subplot(3,NUM_SHOW,2*NUM_SHOW+i+1)\n",
    "        img=pred[i,0,:,:].data.numpy()\n",
    "        #img = np.exp(img)\n",
    "        imshow_noax(img)\n",
    "    break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(loader, model):\n",
    "    ep = 1e-7\n",
    "\n",
    "    thresh_1 = 0\n",
    "    thresh_2 = 0\n",
    "    abs_diff = 0\n",
    "    rmse = 0\n",
    "\n",
    "    for t,(x,y) in enumerate(loader):\n",
    "        x_var=Variable(x.type(dtype),requires_grad=False)\n",
    "        y_var=Variable(y.type(dtype),requires_grad=False)\n",
    "        model.train(False)\n",
    "        x1 = resnet50(x_var)\n",
    "        pred = model(x1)\n",
    "\n",
    "        #print(y_var.data.cpu().numpy())\n",
    "        y_var=y_var.data.cpu().numpy()\n",
    "        y_var = np.exp(y_var) + ep\n",
    "        pred=pred.data.cpu().numpy() + ep\n",
    "        num_var = np.shape(y_var)[0]*np.shape(y_var)[1]*np.shape(y_var)[2]\n",
    "\n",
    "        # threshold\n",
    "        thresh_mat = np.zeros_like(y_var)\n",
    "        thresh_mat[np.maximum(y_var / pred, pred / y_var) < 1.25] = 1\n",
    "        thresh_1 += np.sum(thresh_mat)\n",
    "        thresh_2 += num_var\n",
    "        #print('t1 = %d, t2 = %d', thresh_1, thresh_2)\n",
    "\n",
    "        # relative absolute diffe\n",
    "        abs_diff += np.sum(np.absolute(y_var - pred) / y_var) / num_var\n",
    "\n",
    "        rmse += np.sqrt(np.sum((y_var - pred) * (y_var - pred)) / num_var)\n",
    "        \n",
    "\n",
    "\n",
    "    abs_diff /= len(loader)\n",
    "    rmse /= len(loader)\n",
    "\n",
    "    print('percentage within threshold: ', thresh_1 / thresh_2)\n",
    "    print('relative absolute diff = ', abs_diff)\n",
    "    print('rmse = ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate(loader_val, upsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert(1==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
